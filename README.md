# MINI-TORCH

This is my implementation of mini-pytorch from scratch.

I followed tutorial in `Cornell CS5781: Machine Learning Engineering` to finish this project. 

Main features:

- tensor
    - tuple index
    - auto broadcast
    - reshape, view, permute
    - auto-diff and backpropagation
    - various operators and tensor functions
- nn
    - conv1d
    - conv2d
    - dropout
    - pooling
    - Linear
    - various nonlinear activations
    - module
    - parameter
- tensor ops
    - map
    - zip
    - reduce
- acceleration
    - cpu: fast ops-parallel computation
    - gpu: cuda ops

## SOME VISULAZATION

`1.train process`

<img src="Module-3/result/GPU/ezgif.com-gif-maker.gif">

`2.loss change`

<img src="Module-3/result/GPU/loss.png" width=400>

`3.tensor graph`

<img src="Module-1/result/structure.jpg" width=800>



